{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW 1 for Projects in ML and AI"
      ],
      "metadata": {
        "id": "8OffYHv8bgin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing dependencyes\n",
        "\n",
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "Ua44PO2dcaf_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive and set up kaggle API\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/.kaggle/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSdh4IlCdVWV",
        "outputId": "48e9aeef-9c24-4782-e27c-b4fbb6c0aff2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install dataset and unzip\n",
        "\n",
        "!rm -r dataset\n",
        "\n",
        "!kaggle datasets download -d saumitgp/occupancy-detection-dataset\n",
        "!mkdir dataset\n",
        "!unzip occupancy-detection-dataset.zip -d dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R-m5S4PcoKF",
        "outputId": "51cba3b8-78bd-49b3-ba30-cb537514bd80"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading occupancy-detection-dataset.zip to /content\n",
            "\r  0% 0.00/213k [00:00<?, ?B/s]\n",
            "\r100% 213k/213k [00:00<00:00, 71.1MB/s]\n",
            "Archive:  occupancy-detection-dataset.zip\n",
            "  inflating: dataset/OccupancyData/DataTest.csv  \n",
            "  inflating: dataset/OccupancyData/DataTraining.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().any()"
      ],
      "metadata": {
        "id": "Auu8uphBolGL",
        "outputId": "42db9ac6-88ab-4e3c-a9d5-82b7a533366d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date             False\n",
              "Temperature      False\n",
              "Humidity         False\n",
              "Light            False\n",
              "CO2              False\n",
              "HumidityRatio    False\n",
              "Occupancy        False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# the balance is weird, I will merge the train and test files first and split them to 8:2\n",
        "df = pd.concat([pd.read_csv('dataset/OccupancyData/DataTraining.csv',index_col=[0]),\n",
        "                pd.read_csv('dataset/OccupancyData/DataTest.csv',index_col=[0])])\n",
        "X = df.drop(columns=['date'])\n",
        "y = X.pop('Occupancy')\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.2,random_state=0)\n"
      ],
      "metadata": {
        "id": "-714A7MMeozn"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYuKQexgLgXy"
      },
      "source": [
        "Task 1 (10 points): Describe a machine learning problem that you would like to solve using \n",
        "Logistic Regression. Clearly state why Logistic regression is the best choice for solving this \n",
        "problem.\n",
        "\n",
        "## Task 1\n",
        "\n",
        "The problem of detecting occupancy in a room (classificaion) can be solved using a classification algorithm and training on various features, such as light, co2, temperature, and humidity of a room"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuEdw9uJLgXz"
      },
      "source": [
        "Task 2 (20 points): Pick a publicly available dataset (except The Titanic Dataset because we \n",
        "already discussed that in class) that you will use to solve this problem. You must provide a link \n",
        "to the dataset and perform necessary Exploratory Data Analysis (EDA). Clearly demonstrate the \n",
        "steps you follow for your EDA with a justification of why these were required. For example, if \n",
        "the dataset has lot of missing values, then why did you use a specific technique when handling \n",
        "missing data. This task may include data visualization (Check this link : \n",
        "https://www.geeksforgeeks.org/top-8-python-libraries-for-data-visualization/).\n",
        "\n",
        "## Task 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# the balance is weird, I will merge the train and test files first and split them to 8:2\n",
        "df = pd.concat([pd.read_csv('dataset/OccupancyData/DataTraining.csv',index_col=[0]),\n",
        "                pd.read_csv('dataset/OccupancyData/DataTest.csv',index_col=[0])])\n",
        "X = df.drop(columns=['date'])\n",
        "y = X.pop('Occupancy')\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.2,random_state=0)\n"
      ],
      "metadata": {
        "id": "is1vZ6Jto0Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train,y_train)\n",
        "print(clf.score(X_train,y_train))\n",
        "print(clf.score(X_test,y_test))"
      ],
      "metadata": {
        "id": "P_dKmiNNo3eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ucln5wHLgX0"
      },
      "source": [
        "Task 3 (35 points): Implement, Logistic Regression in this step. Clearly write your cost function \n",
        "and derivatives before implementing gradient descent. Do not use any built-in packages for this \n",
        "step. You can use the vectorization techniques demonstrated in class. Implement any 2 variants \n",
        "of gradient descent in their original form. (Refer to the research paper discussed in class).\n",
        "\n",
        "## Task 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "class LogisticRegression():\n",
        "    def __init__(self):\n",
        "        # initialize as random zeros. Using 100 weights, but for each dataset with N features we can use the first N weights and biases\n",
        "        self.w = np.zeroes(100)\n",
        "        self.b = np.zeros(100)\n",
        "    def "
      ],
      "metadata": {
        "id": "3EwmSuL8o4sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R35gBniLgX0"
      },
      "source": [
        "Task 4 (35 points): Pick any 2 optimization algorithms that are used to optimize the ‘vanilla’\n",
        "gradient descent. Implement both. You may implement these algorithms yourself OR use a \n",
        "package. In your conclusion, compare both optimization techniques/algorithms with respect to \n",
        "the results you achieve. Also compare these results with the original implementation of \n",
        "gradient descent (Task 3 above). Describe why or why not should we use optimization \n",
        "algorithms for the task at hand\n",
        "\n",
        "## Task 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K_N5MbwRLjk0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWc3VK2jLgX9"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}