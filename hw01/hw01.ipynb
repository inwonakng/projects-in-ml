{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW 1 for Projects in ML and AI"
      ],
      "metadata": {
        "id": "8OffYHv8bgin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing dependencyes\n",
        "\n",
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "Ua44PO2dcaf_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive and set up kaggle API\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/.kaggle/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "CSdh4IlCdVWV",
        "outputId": "48e9aeef-9c24-4782-e27c-b4fbb6c0aff2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ~/.kaggle"
      ],
      "metadata": {
        "id": "Y6qpawXxeITk",
        "outputId": "c993a0cb-394c-4d88-dd73-eae0cf254ce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install dataset and unzip\n",
        "\n",
        "!kaggle datasets download -d fabriciojoc/fast-furious-malware-data-stream\n",
        "!mkdir dataset\n",
        "!unzip fast-furious-malware-data-stream.zip -d dataset"
      ],
      "metadata": {
        "id": "-R-m5S4PcoKF",
        "outputId": "fc14edf5-c8a4-44c6-b3f8-051f5d21d167",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fast-furious-malware-data-stream.zip to /content\n",
            " 10% 813M/8.19G [00:07<01:07, 118MB/s]\n",
            "User cancelled operation\n",
            "mkdir: cannot create directory ‘dataset’: File exists\n",
            "Archive:  fast-furious-malware-data-stream.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of fast-furious-malware-data-stream.zip or\n",
            "        fast-furious-malware-data-stream.zip.zip, and cannot find fast-furious-malware-data-stream.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('dataset/chocolate_bars.csv')\n",
        "\n",
        "for c in df.columns:\n",
        "    print(c,df[c].unique().shape[0])"
      ],
      "metadata": {
        "id": "-714A7MMeozn",
        "outputId": "bc23134a-b8bd-4c47-bf27-b68db14f100f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id 630\n",
            "manufacturer 580\n",
            "company_location 67\n",
            "year_reviewed 16\n",
            "bean_origin 62\n",
            "bar_name 1605\n",
            "cocoa_percent 46\n",
            "num_ingredients 7\n",
            "ingredients 22\n",
            "review 2487\n",
            "rating 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "clf = LogisticRegression()\n",
        "X_train, X_test, y_train, y_test = train_test_split(df)\n"
      ],
      "metadata": {
        "id": "cHSTBwMie0Ik"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYuKQexgLgXy"
      },
      "source": [
        "Task 1 (10 points): Describe a machine learning problem that you would like to solve using \n",
        "Logistic Regression. Clearly state why Logistic regression is the best choice for solving this \n",
        "problem.\n",
        "\n",
        "## Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuEdw9uJLgXz"
      },
      "source": [
        "Task 2 (20 points): Pick a publicly available dataset (except The Titanic Dataset because we \n",
        "already discussed that in class) that you will use to solve this problem. You must provide a link \n",
        "to the dataset and perform necessary Exploratory Data Analysis (EDA). Clearly demonstrate the \n",
        "steps you follow for your EDA with a justification of why these were required. For example, if \n",
        "the dataset has lot of missing values, then why did you use a specific technique when handling \n",
        "missing data. This task may include data visualization (Check this link : \n",
        "https://www.geeksforgeeks.org/top-8-python-libraries-for-data-visualization/).\n",
        "\n",
        "## Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ucln5wHLgX0"
      },
      "source": [
        "Task 3 (35 points): Implement, Logistic Regression in this step. Clearly write your cost function \n",
        "and derivatives before implementing gradient descent. Do not use any built-in packages for this \n",
        "step. You can use the vectorization techniques demonstrated in class. Implement any 2 variants \n",
        "of gradient descent in their original form. (Refer to the research paper discussed in class).\n",
        "\n",
        "## Task 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R35gBniLgX0"
      },
      "source": [
        "Task 4 (35 points): Pick any 2 optimization algorithms that are used to optimize the ‘vanilla’\n",
        "gradient descent. Implement both. You may implement these algorithms yourself OR use a \n",
        "package. In your conclusion, compare both optimization techniques/algorithms with respect to \n",
        "the results you achieve. Also compare these results with the original implementation of \n",
        "gradient descent (Task 3 above). Describe why or why not should we use optimization \n",
        "algorithms for the task at hand\n",
        "\n",
        "## Task 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K_N5MbwRLjk0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWc3VK2jLgX9"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}