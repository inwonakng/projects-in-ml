{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f87mR-Qv3tPV"
      },
      "source": [
        "# Projects in ML HW 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLtMV-C13tPZ"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "We discussed how we can formulate RL problems as an MDP. Describe any\n",
        "real-world application that can be formulated as an MDP. Describe the state space, action\n",
        "space, transition model, and rewards for that problem. You do not need to be precise in the\n",
        "description of the transition model and reward (no formula is needed). Qualitative description\n",
        "is enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa6nKCqT3tPb"
      },
      "source": [
        "One real-world application of MDP I can think of is any type of diasastor control. I think nuclear powerplants are a well known example of such an application. \n",
        "\n",
        "The **state space** of a nuclear powerplant can be state of its sensors.\n",
        "\n",
        "The **action space** of a nuclear poewrplant can be a possible set of actions that can be automated. (i.e. alert operator, stop current action, cooldown mode, etc)\n",
        "\n",
        "The **transition model** can be composed of the sensor outputs *after* the action is changed. For example, if the coolant is too hot `{...state, coolanttemp: 99}`, the state transition after the action of cooling it down could be into `{...state, coolanttemp: 50}`. Each sensor or group of sensors should have some action linked to it, in the example it is the case of the 'coolant temp sensor' and 'cooling system'.\n",
        "\n",
        "The **reward** in this case would be minimizing risk, as nuclear powerplants generally produce plenty power, but a single mistake could bring devastating outcome"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Teoz3yub3tPe"
      },
      "source": [
        "## Task 2 \n",
        "\n",
        "RL is used in various sectors - Healthcare, recommender systems and trading\n",
        "are a few of those. Pick one of the three areas. Explain one of the problems in any of these\n",
        "domains that can be more effectively solved by reinforcement learning. Find an open-source\n",
        "project (if any) that has addressed this problem. Explain this project in detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEQDpp5E3tPg"
      },
      "source": [
        "Reinforcement learning is well suited to healtcare, as the physician needs to continue monitoring the patient's state and choose the best actions to improve their state. One problem that exists in this domain is that there is often not enough data to sufficiently train a model, due to the sensitive nature of the domain.\n",
        "\n",
        "I found this open source project from Microsoft called \"Med-Deadend\" https://github.com/microsoft/med-deadend. \n",
        "\n",
        "This project addresses a problem in ML with healthcare -- lack of training data -- and re-scopes the problem so that a good model can be learned with smaller amounts of data. This project focuses on reinforcement learning on data from critically ill patients, and learns to predict a \"dead-end\", which means the patient will go in critical condition. In essence, the purpose of this model is to identify which procedures must be taken to **prevent** such dead ends. \n",
        "\n",
        "The problem is modeled such that a positive outcome gets a reward of 1, and a negative outcome gets a reward of -1. The state space is compoesd of various features of a patient, such as their blodd pressure or hear rate. They also make use of a specific variety of reinforcement learning, called offline reinforcement learning where the learning happens with existing data. Usually, this approach can still take a large amount of data to train sufficiently, but by scoping the problem to a specific domain, the authors show that their model does indeed work. \n",
        "\n",
        "Furthur details can also be found in https://www.microsoft.com/en-us/research/blog/using-reinforcement-learning-to-identify-high-risk-states-and-treatments-in-healthcare/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JTa5jw3tPi"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "Implement the game of tic-tac-toe (write a class that implements an agent playing Tic Tac Toe and learning its Q function) using the Q-learning technique (see the resources/links provided in class for more details). Clearly describe your evaluation metric and demonstrate a few runs. You might need to use some online resources to proceed on this. Do not forget to cite those."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "board = np.zeros((3,3),dtype=int)\n",
        "# board += np.eye(3)[::-1]\n",
        "# board[:,1] = 2\n",
        "\n",
        "# board[0,0] = 'X'\n",
        "# board[1,1] = 'X'\n",
        "# board[2,2] = 'X'\n",
        "\n",
        "horizontal = any(map(lambda i: all(board[i] == 1), range(3))) \n",
        "vertical = any(map(lambda i: all(board[:,i] == 1), range(3)))\n",
        "\n",
        "diag1 = all(board[np.eye(3,dtype=bool)] == 1)\n",
        "diag2 = all(board[np.eye(3,dtype=bool)[::-1]] == 1)\n",
        "\n",
        "# display(board)\n",
        "# horizontal,vertical,diag1,diag2\n",
        "\n",
        "# board\n",
        "\n",
        "# board[np.eye(3,dtype=bool)]\n",
        "\n",
        "# print('\\n'.join(map(lambda p: '\\t'.join(p),board)))\n",
        "# list(map(lambda p: ),board))\n",
        "\n",
        "# print('\\t|'+'\\t'.join(map(str,range(3))))\n",
        "# print('________|'+'________'*3)\n",
        "# for i,row in enumerate(board):\n",
        "#     print(f'{i}\\t|'+'\\t'.join(map(lambda id: str(id),row)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OV5Rl2Rg4kEF",
        "outputId": "e5b4ee05-8e68-4bb5-d998-4ec46a4471b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0  1  2\n",
            "0  0  0  0\n",
            "1  0  0  0\n",
            "2  0  0  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XvU48je3tPj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# ACTIONS = \n",
        "\n",
        "class Player:\n",
        "    def __init__(self,id,sym):\n",
        "        self.sym = sym\n",
        "        self.id = id\n",
        "\n",
        "class TicTacToe:\n",
        "    def __init__(self,p1,p2):\n",
        "        self.board = np.zeros((3,3),dtype=int)\n",
        "        self.actions = list(product(range(3),range(3)))\n",
        "\n",
        "\n",
        "    def is_winner(self,player):\n",
        "        horizontal = any(map(lambda i: all(self.board[i] == player.id), range(3))) \n",
        "        vertical = any(map(lambda i: all(self.board[:,i] == player.id), range(3)))\n",
        "        diag1 = all(self.board[np.eye(3,dtype=bool)] == player.id)\n",
        "        diag2 = all(self.board[np.eye(3,dtype=bool)[::-1]] == player.id)\n",
        "\n",
        "    def show_board(self):\n",
        "        print(pd.DataFrame(self.board))\n",
        "\n",
        "    def available_moves(self):\n",
        "        return filter(lambda loc: self.board[loc] == 0,self.actions)\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qMkUNl744Rzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WT0bJej_4STZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}